# First Order Algorithms:
1. First-order optimization algorithms explicitly involve using the first derivative (gradient) to choose the direction to move in the search space.
2. The step size is a hyperparameter that controls how far to move in the search space. A step size that is too small results in a search that takes a long time and can get stuck, whereas a step size that is too large will result in zig-zagging or bouncing around the search space, missing the optima completely.
